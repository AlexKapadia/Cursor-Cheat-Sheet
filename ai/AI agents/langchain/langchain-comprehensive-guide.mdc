---
alwaysApply: false
---

# LangChain - Comprehensive AI Agent Development Guide

## Paper Metadata
- **Title:** LangChain Documentation - Building AI Agents with LLMs
- **Source:** LangChain Official Documentation
- **Version:** LangChain v1.x
- **Language:** Python 3.10+
- **Documentation URL:** https://docs.langchain.com/
- **Keywords:** AI Agents, LLMs, LangChain, LangGraph, Tool Calling, RAG, Memory, Middleware, Context Engineering

## Abstract / Summary

LangChain is the easiest way to start building agents and applications powered by Large Language Models (LLMs). With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and hundreds of other providers. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.

LangChain agents are built on top of LangGraph, providing durable execution, streaming, human-in-the-loop support, persistence, and more. The framework is designed to be easy to get started with while also being flexible and production-ready.

## Problem Statement

### Problem Definition

Building reliable AI agents that can interact with external systems, maintain context, and make intelligent decisions is challenging. Developers face several key problems:

1. **Model Provider Lock-in:** Different providers expose different APIs, model parameters, and message formats
2. **Complex Agent Orchestration:** Building agents that can reason, use tools, and maintain state requires complex orchestration
3. **Context Management:** Managing what information agents see, when they see it, and how it's presented
4. **Reliability:** Building agents that are reliable enough for production use
5. **Integration Complexity:** Integrating LLMs with external data sources, APIs, and tools

### Motivation

Large Language Models (LLMs) are powerful, but they have limitations:
- **Finite context** - they can't ingest entire corpora at once
- **Static knowledge** - their training data is frozen at a point in time
- **No direct actions** - they can't interact with external systems directly

LangChain addresses these limitations by:
- Standardizing model interfaces across providers
- Providing agent abstractions that handle orchestration
- Enabling tool calling for external interactions
- Supporting memory and context management
- Facilitating retrieval-augmented generation (RAG)

### Challenges

1. **Context Engineering:** Providing the right information and tools in the right format so the LLM can accomplish tasks
2. **Reliability:** Making agents reliable enough for production use
3. **Cost Management:** Optimizing model calls and token usage
4. **Latency:** Balancing functionality with response time
5. **State Management:** Maintaining conversation state and long-term memory

### Scope

LangChain focuses on:
- **Agent Development:** Building AI agents that can reason and use tools
- **Model Integration:** Standardizing interactions with LLM providers
- **Tool Calling:** Enabling agents to interact with external systems
- **Memory Management:** Short-term and long-term memory for agents
- **Context Engineering:** Controlling what information agents see and when
- **Production Features:** Streaming, persistence, observability, testing

### Assumptions

- Python 3.10+ is available
- Access to at least one LLM provider (OpenAI, Anthropic, Google, etc.)
- Understanding of basic Python programming
- Familiarity with LLM concepts (optional but helpful)

## Key Concepts and Techniques

### Core Concepts

1. **Agents:** Autonomous systems that can reason, use tools, and interact with users
2. **Tools:** Functions that agents can call to interact with external systems
3. **Models:** LLM providers (OpenAI, Anthropic, Google, etc.) accessed through standardized interfaces
4. **Messages:** Structured communication between users, agents, and tools
5. **Memory:** Short-term (conversation state) and long-term (persistent storage) memory
6. **Middleware:** Hooks that intercept agent execution for logging, validation, transformation
7. **Context Engineering:** Providing the right information at the right time in the right format
8. **Structured Output:** Guaranteeing agent responses conform to specific schemas
9. **Streaming:** Real-time output as the agent processes requests
10. **Retrieval-Augmented Generation (RAG):** Enhancing LLM responses with external knowledge

### Architecture Patterns

1. **Agent Loop:** Model call → Tool execution → Model call (repeats until completion)
2. **Tool Calling:** Agents decide when and which tools to use based on context
3. **Middleware Hooks:** Intercept execution at specific points (before/after model, before/after agent)
4. **Context Sources:** State (short-term), Store (long-term), Runtime Context (static configuration)
5. **Multi-Agent Patterns:** Tool calling (supervisor calls sub-agents) and Handoffs (agents transfer control)

## Installation and Setup

### Basic Installation

```bash
# Install LangChain core package
pip install -U langchain
# Requires Python 3.10+

# Or using uv
uv add langchain
```

### Provider-Specific Installations

LangChain provides integrations to hundreds of LLMs and thousands of other integrations. These live in independent provider packages:

```bash
# Installing the OpenAI integration
pip install -U langchain-openai

# Installing the Anthropic integration
pip install -U langchain-anthropic

# Installing the Google integration
pip install -U langchain-google-genai
```

### Environment Setup

Set up API keys as environment variables:

```bash
# For Anthropic
export ANTHROPIC_API_KEY=your_key_here

# For OpenAI
export OPENAI_API_KEY=your_key_here

# For Google
export GOOGLE_API_KEY=your_key_here
```

### Additional Dependencies

For specific features, you may need additional packages:

```bash
# For memory/persistence
pip install langgraph

# For testing
pip install agentevals

# For MCP integration
pip install langchain-mcp-adapters
```

## Quickstart Guide

### Basic Agent Example

The simplest agent can be created in under 10 lines of code:

```python
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[get_weather],
    system_prompt="You are a helpful assistant",
)

# Run the agent
result = agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather in sf"}]}
)
```

### Production-Ready Agent Example

A more complete example with all production features:

```python
from dataclasses import dataclass
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model
from langchain.tools import tool, ToolRuntime
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents.structured_output import ToolStrategy

# Define system prompt
SYSTEM_PROMPT = """You are an expert weather forecaster, who speaks in puns.

You have access to two tools:

- get_weather_for_location: use this to get the weather for a specific location
- get_user_location: use this to get the user's location

If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location."""

# Define context schema
@dataclass
class Context:
    """Custom runtime context schema."""
    user_id: str

# Define tools
@tool
def get_weather_for_location(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """Retrieve user information based on user ID."""
    user_id = runtime.context.user_id
    return "Florida" if user_id == "1" else "SF"

# Configure model
model = init_chat_model(
    "claude-sonnet-4-5-20250929",
    temperature=0.5,
    timeout=10,
    max_tokens=1000
)

# Define response format
@dataclass
class ResponseFormat:
    """Response schema for the agent."""
    punny_response: str
    weather_conditions: str | None = None

# Set up memory
checkpointer = InMemorySaver()

# Create agent
agent = create_agent(
    model=model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ToolStrategy(ResponseFormat),
    checkpointer=checkpointer
)

# Run agent with thread ID for persistence
config = {"configurable": {"thread_id": "1"}}

response = agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather outside?"}]},
    config=config,
    context=Context(user_id="1")
)

print(response['structured_response'])
```

## Core Components

### Agents

Agents are autonomous systems that can reason, use tools, and interact with users. They follow a loop pattern:

1. **Model Call:** The agent calls the LLM with a prompt and available tools
2. **Tool Execution:** If the model requests tools, they are executed
3. **Response:** Tool results are returned to the model
4. **Repeat:** The loop continues until the model decides to finish

#### Creating Agents

```python
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4o",  # or any supported model
    tools=[...],  # List of tools
    system_prompt="You are a helpful assistant",  # Optional
    middleware=[...],  # Optional middleware
    checkpointer=...,  # Optional for memory
    context_schema=...,  # Optional runtime context
    response_format=...,  # Optional structured output
    store=...,  # Optional for long-term memory
)
```

#### Agent Parameters

- **model:** The LLM to use (string or model instance)
- **tools:** List of tools the agent can use
- **system_prompt:** Instructions for the agent's behavior
- **middleware:** List of middleware functions/classes
- **checkpointer:** For conversation persistence
- **context_schema:** Schema for runtime context
- **response_format:** Schema for structured output
- **store:** For long-term memory storage

### Models

LangChain standardizes model interfaces across providers. You can use models from:

- OpenAI (GPT-4, GPT-3.5, etc.)
- Anthropic (Claude Sonnet, Claude Opus, etc.)
- Google (Gemini, PaLM, etc.)
- And hundreds more

#### Initializing Models

```python
from langchain.chat_models import init_chat_model

# Simple initialization
model = init_chat_model("gpt-4o")

# With configuration
model = init_chat_model(
    "claude-sonnet-4-5-20250929",
    temperature=0.5,
    timeout=10,
    max_tokens=1000
)
```

#### Model Configuration

Common parameters:
- **temperature:** Controls randomness (0.0-2.0)
- **max_tokens:** Maximum tokens in response
- **timeout:** Request timeout in seconds
- **streaming:** Enable streaming responses

### Tools

Tools are functions that agents can call to interact with external systems. They can:
- Access databases
- Call APIs
- Perform calculations
- Read/write files
- Access runtime context
- Read/write to memory stores

#### Creating Tools

```python
from langchain.tools import tool

@tool
def search_database(query: str) -> str:
    """Search the database for information.
    
    Args:
        query: The search query string
    """
    # Implementation
    return results
```

#### Tools with Runtime Context

```python
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime

@dataclass
class Context:
    user_id: str
    api_key: str

@tool
def fetch_user_data(
    query: str,
    runtime: ToolRuntime[Context]
) -> str:
    """Fetch data using runtime context."""
    user_id = runtime.context.user_id
    api_key = runtime.context.api_key
    # Use context to fetch data
    return results
```

#### Tools with State Access

```python
from langchain.tools import tool, ToolRuntime

@tool
def check_authentication(runtime: ToolRuntime) -> str:
    """Check if user is authenticated."""
    current_state = runtime.state
    is_authenticated = current_state.get("authenticated", False)
    return "Authenticated" if is_authenticated else "Not authenticated"
```

#### Tools with Store Access

```python
from langchain.tools import tool, ToolRuntime
from langgraph.store.memory import InMemoryStore

@dataclass
class Context:
    user_id: str

@tool
def get_preference(
    preference_key: str,
    runtime: ToolRuntime[Context]
) -> str:
    """Get user preference from Store."""
    user_id = runtime.context.user_id
    store = runtime.store
    existing_prefs = store.get(("preferences",), user_id)
    
    if existing_prefs:
        value = existing_prefs.value.get(preference_key)
        return f"{preference_key}: {value}" if value else f"No preference set for {preference_key}"
    return "No preferences found"
```

#### Tools Writing to State

```python
from langchain.tools import tool, ToolRuntime
from langgraph.types import Command

@tool
def authenticate_user(
    password: str,
    runtime: ToolRuntime
) -> Command:
    """Authenticate user and update State."""
    if password == "correct":
        return Command(update={"authenticated": True})
    else:
        return Command(update={"authenticated": False})
```

#### Tools Writing to Store

```python
from langchain.tools import tool, ToolRuntime

@tool
def save_preference(
    preference_key: str,
    preference_value: str,
    runtime: ToolRuntime[Context]
) -> str:
    """Save user preference to Store."""
    user_id = runtime.context.user_id
    store = runtime.store
    
    # Read existing preferences
    existing_prefs = store.get(("preferences",), user_id)
    
    # Merge with new preference
    prefs = existing_prefs.value if existing_prefs else {}
    prefs[preference_key] = preference_value
    
    # Write to Store
    store.put(("preferences",), user_id, prefs)
    
    return f"Saved preference: {preference_key} = {preference_value}"
```

### Messages

Messages are structured communication between users, agents, and tools. LangChain supports:

- **HumanMessage:** User input
- **AIMessage:** Agent responses
- **ToolMessage:** Tool execution results
- **SystemMessage:** System instructions

#### Message Structure

```python
from langchain.messages import HumanMessage, AIMessage, ToolMessage

# User message
user_msg = HumanMessage(content="What's the weather?")

# AI message with tool calls
ai_msg = AIMessage(
    content="",
    tool_calls=[{
        "name": "get_weather",
        "args": {"city": "SF"},
        "id": "call_1"
    }]
)

# Tool message
tool_msg = ToolMessage(
    content="It's sunny!",
    tool_call_id="call_1"
)
```

### Memory

LangChain supports two types of memory:

1. **Short-term Memory:** Conversation state within a session (via checkpointer)
2. **Long-term Memory:** Persistent storage across sessions (via store)

#### Short-term Memory (Checkpointer)

```python
from langgraph.checkpoint.memory import InMemorySaver

# For development/testing
checkpointer = InMemorySaver()

# For production (PostgreSQL example)
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver

checkpointer = AsyncPostgresSaver.from_conn_string(
    "postgresql://user:pass@localhost/db"
)

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    checkpointer=checkpointer
)

# Use thread_id for conversation persistence
config = {"configurable": {"thread_id": "conversation_1"}}
result = agent.invoke(
    {"messages": [HumanMessage("Hello")]},
    config=config
)
```

#### Long-term Memory (Store)

```python
from langgraph.store.memory import InMemoryStore

# For development/testing
store = InMemoryStore()

# For production, use a database-backed store
# (implementation depends on your database)

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    store=store,
    context_schema=Context
)

# Store data
store.put(
    ("users",),  # Namespace
    "user_123",  # Key
    {"name": "John", "preferences": {...}}  # Data
)

# Retrieve data
item = store.get(("users",), "user_123")
```

### Streaming

Streaming allows real-time output as the agent processes requests:

```python
# Stream agent responses
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "Tell me a story"}]}
):
    print(chunk)
```

#### Streaming Modes

1. **"messages":** Stream individual messages
2. **"tool_calls":** Stream tool calls as they happen
3. **"custom":** Custom streaming via middleware

```python
# Stream messages
for chunk in agent.stream(
    {"messages": [...]},
    stream_mode="messages"
):
    if "messages" in chunk:
        print(chunk["messages"][-1].content)
```

### Structured Output

Structured output guarantees agent responses conform to specific schemas:

```python
from pydantic import BaseModel, Field
from langchain.agents.structured_output import ToolStrategy

class CustomerSupportTicket(BaseModel):
    """Structured ticket information."""
    category: str = Field(description="Issue category")
    priority: str = Field(description="Urgency level")
    summary: str = Field(description="One-sentence summary")
    customer_sentiment: str = Field(description="Emotional tone")

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    response_format=ToolStrategy(CustomerSupportTicket)
)

result = agent.invoke({"messages": [...]})
ticket = result['structured_response']  # CustomerSupportTicket instance
```

## Middleware

Middleware allows you to intercept agent execution at specific points to add cross-cutting concerns like logging, validation, caching, and transformation.

### Middleware Hooks

LangChain provides two styles of hooks:

1. **Node-style hooks:** Run sequentially at specific execution points
   - `before_agent`: Before agent starts (once per invocation)
   - `before_model`: Before each model call
   - `after_model`: After each model response
   - `after_agent`: After agent completes (once per invocation)

2. **Wrap-style hooks:** Run around each model or tool call
   - `wrap_model_call`: Around each model call
   - `wrap_tool_call`: Around each tool call

### Creating Middleware

#### Decorator-Based Middleware

```python
from langchain.agents.middleware import (
    before_model,
    after_model,
    wrap_model_call,
    AgentState,
    ModelRequest,
    ModelResponse,
)
from langgraph.runtime import Runtime
from typing import Any, Callable

# Node-style hook
@before_model
def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    print(f"About to call model with {len(state['messages'])} messages")
    return None

# Wrap-style hook
@wrap_model_call
def retry_model(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse],
) -> ModelResponse:
    for attempt in range(3):
        try:
            return handler(request)
        except Exception as e:
            if attempt == 2:
                raise
            print(f"Retry {attempt + 1}/3 after error: {e}")

agent = create_agent(
    model="gpt-4o",
    middleware=[log_before_model, retry_model],
    tools=[...],
)
```

#### Class-Based Middleware

```python
from langchain.agents.middleware import (
    AgentMiddleware,
    AgentState,
    ModelRequest,
    ModelResponse,
)
from langgraph.runtime import Runtime
from typing import Any, Callable

class LoggingMiddleware(AgentMiddleware):
    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        print(f"About to call model with {len(state['messages'])} messages")
        return None

    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        print(f"Model returned: {state['messages'][-1].content}")
        return None

agent = create_agent(
    model="gpt-4o",
    middleware=[LoggingMiddleware()],
    tools=[...],
)
```

### Built-in Middleware

#### Summarization Middleware

Automatically condenses conversation history when it gets too long:

```python
from langchain.agents.middleware import SummarizationMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[
        SummarizationMiddleware(
            model="gpt-4o-mini",
            trigger={"tokens": 4000},
            keep={"messages": 20},
        ),
    ],
)
```

#### PII Detection Middleware

Detects and handles Personally Identifiable Information:

```python
from langchain.agents.middleware import PIIMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[
        PIIMiddleware(
            "email",
            strategy="redact",
            apply_to_input=True,
        ),
        PIIMiddleware(
            "credit_card",
            strategy="mask",
            apply_to_input=True,
        ),
    ],
)
```

**PII Strategies:**
- `redact`: Replace with `[REDACTED_TYPE]`
- `mask`: Partially obscure (e.g., last 4 digits)
- `hash`: Replace with deterministic hash
- `block`: Raise exception when detected

#### Human-in-the-Loop Middleware

Requires human approval before executing sensitive operations:

```python
from langchain.agents.middleware import HumanInTheLoopMiddleware
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool, send_email_tool, delete_database_tool],
    middleware=[
        HumanInTheLoopMiddleware(
            interrupt_on={
                "send_email": True,
                "delete_database": True,
                "search": False,
            }
        ),
    ],
    checkpointer=InMemorySaver(),
)

# Agent will pause and wait for approval
config = {"configurable": {"thread_id": "some_id"}}
result = agent.invoke(
    {"messages": [{"role": "user", "content": "Send an email"}]},
    config=config
)

# Resume with approval
result = agent.invoke(
    Command(resume={"decisions": [{"type": "approve"}]}),
    config=config
)
```

**Decision Types:**
- `approve`: Execute as-is
- `edit`: Execute with modifications
- `reject`: Reject with feedback

### Custom State Schema

Middleware can extend the agent's state with custom properties:

```python
from langchain.agents.middleware import AgentState, before_model, after_model
from typing_extensions import NotRequired
from typing import Any

class CustomState(AgentState):
    model_call_count: NotRequired[int]
    user_id: NotRequired[str]

@before_model(state_schema=CustomState)
def check_call_limit(state: CustomState, runtime: Runtime) -> dict[str, Any] | None:
    count = state.get("model_call_count", 0)
    if count > 10:
        return {"jump_to": "end"}
    return None

@after_model(state_schema=CustomState)
def increment_counter(state: CustomState, runtime: Runtime) -> dict[str, Any] | None:
    return {"model_call_count": state.get("model_call_count", 0) + 1}
```

### Execution Order

When using multiple middleware, they execute in order:

```python
agent = create_agent(
    model="gpt-4o",
    middleware=[middleware1, middleware2, middleware3],
    tools=[...],
)
```

**Execution flow:**
1. `before_*` hooks: First to last
2. `wrap_*` hooks: Nested (first middleware wraps all others)
3. `after_*` hooks: Last to first (reverse)

### Agent Jumps

To exit early from middleware, return a dictionary with `jump_to`:

**Available jump targets:**
- `'end'`: Jump to the end of agent execution
- `'tools'`: Jump to the tools node
- `'model'`: Jump to the model node

```python
@after_model(can_jump_to=["end"])
def check_for_blocked(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    last_message = state["messages"][-1]
    if "BLOCKED" in last_message.content:
        return {
            "messages": [AIMessage("I cannot respond to that request.")],
            "jump_to": "end"
        }
    return None
```

## Context Engineering

Context engineering is providing the right information and tools in the right format so the LLM can accomplish a task. This is the number one job of AI Engineers.

### The Agent Loop

A typical agent loop consists of two main steps:

1. **Model call** - calls the LLM with a prompt and available tools
2. **Tool execution** - executes the tools that the LLM requested

This loop continues until the LLM decides to finish.

### Context Types

| Context Type | What You Control | Transient or Persistent |
|--------------|------------------|--------------------------|
| **Model Context** | What goes into model calls (instructions, message history, tools, response format) | Transient |
| **Tool Context** | What tools can access and produce (reads/writes to state, store, runtime context) | Persistent |
| **Life-cycle Context** | What happens between model and tool calls (summarization, guardrails, logging, etc.) | Persistent |

### Data Sources

| Data Source | Also Known As | Scope | Examples |
|-------------|---------------|-------|----------|
| **Runtime Context** | Static configuration | Conversation-scoped | User ID, API keys, database connections, permissions |
| **State** | Short-term memory | Conversation-scoped | Current messages, uploaded files, authentication status |
| **Store** | Long-term memory | Cross-conversation | User preferences, extracted insights, memories |

### Model Context

Control what goes into each model call - instructions, available tools, which model to use, and output format.

#### System Prompt

The system prompt sets the LLM's behavior and capabilities. You can make it dynamic:

```python
from langchain.agents.middleware import dynamic_prompt, ModelRequest

@dynamic_prompt
def state_aware_prompt(request: ModelRequest) -> str:
    message_count = len(request.messages)
    base = "You are a helpful assistant."
    
    if message_count > 10:
        base += "\nThis is a long conversation - be extra concise."
    
    return base
```

#### Messages

Inject context into messages:

```python
@wrap_model_call
def inject_file_context(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse]
) -> ModelResponse:
    """Inject context about files user has uploaded."""
    uploaded_files = request.state.get("uploaded_files", [])
    
    if uploaded_files:
        file_descriptions = [
            f"- {file['name']} ({file['type']}): {file['summary']}"
            for file in uploaded_files
        ]
        
        file_context = f"""Files you have access to:
{chr(10).join(file_descriptions)}

Reference these files when answering questions."""
        
        messages = [
            *request.messages,
            {"role": "user", "content": file_context},
        ]
        request = request.override(messages=messages)
    
    return handler(request)
```

#### Tools

Dynamically select tools based on context:

```python
@wrap_model_call
def state_based_tools(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse]
) -> ModelResponse:
    """Filter tools based on conversation State."""
    state = request.state
    is_authenticated = state.get("authenticated", False)
    
    if not is_authenticated:
        tools = [t for t in request.tools if t.name.startswith("public_")]
        request = request.override(tools=tools)
    
    return handler(request)
```

#### Model Selection

Select different models based on context:

```python
from langchain.chat_models import init_chat_model

large_model = init_chat_model("claude-sonnet-4-5-20250929")
standard_model = init_chat_model("gpt-4o")
efficient_model = init_chat_model("gpt-4o-mini")

@wrap_model_call
def state_based_model(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse]
) -> ModelResponse:
    """Select model based on conversation length."""
    message_count = len(request.messages)
    
    if message_count > 20:
        model = large_model
    elif message_count > 10:
        model = standard_model
    else:
        model = efficient_model
    
    request = request.override(model=model)
    return handler(request)
```

#### Response Format

Dynamically select response formats:

```python
from pydantic import BaseModel, Field

class SimpleResponse(BaseModel):
    answer: str

class DetailedResponse(BaseModel):
    answer: str
    reasoning: str
    confidence: float

@wrap_model_call
def state_based_output(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse]
) -> ModelResponse:
    message_count = len(request.messages)
    
    if message_count < 3:
        request = request.override(response_format=SimpleResponse)
    else:
        request = request.override(response_format=DetailedResponse)
    
    return handler(request)
```

### Tool Context

Tools can read from and write to state, store, and runtime context.

#### Reading from State

```python
@tool
def check_authentication(runtime: ToolRuntime) -> str:
    """Check if user is authenticated."""
    current_state = runtime.state
    is_authenticated = current_state.get("authenticated", False)
    return "User is authenticated" if is_authenticated else "User is not authenticated"
```

#### Reading from Store

```python
@tool
def get_preference(
    preference_key: str,
    runtime: ToolRuntime[Context]
) -> str:
    """Get user preference from Store."""
    user_id = runtime.context.user_id
    store = runtime.store
    existing_prefs = store.get(("preferences",), user_id)
    
    if existing_prefs:
        value = existing_prefs.value.get(preference_key)
        return f"{preference_key}: {value}" if value else f"No preference set"
    return "No preferences found"
```

#### Reading from Runtime Context

```python
@tool
def fetch_user_data(
    query: str,
    runtime: ToolRuntime[Context]
) -> str:
    """Fetch data using Runtime Context configuration."""
    user_id = runtime.context.user_id
    api_key = runtime.context.api_key
    db_connection = runtime.context.db_connection
    
    # Use configuration to fetch data
    results = perform_database_query(db_connection, query, api_key)
    return f"Found {len(results)} results for user {user_id}"
```

#### Writing to State

```python
@tool
def authenticate_user(
    password: str,
    runtime: ToolRuntime
) -> Command:
    """Authenticate user and update State."""
    if password == "correct":
        return Command(update={"authenticated": True})
    else:
        return Command(update={"authenticated": False})
```

#### Writing to Store

```python
@tool
def save_preference(
    preference_key: str,
    preference_value: str,
    runtime: ToolRuntime[Context]
) -> str:
    """Save user preference to Store."""
    user_id = runtime.context.user_id
    store = runtime.store
    
    # Read existing preferences
    existing_prefs = store.get(("preferences",), user_id)
    
    # Merge with new preference
    prefs = existing_prefs.value if existing_prefs else {}
    prefs[preference_key] = preference_value
    
    # Write to Store
    store.put(("preferences",), user_id, prefs)
    
    return f"Saved preference: {preference_key} = {preference_value}"
```

### Life-cycle Context

Control what happens **between** the core agent steps - intercepting data flow to implement cross-cutting concerns.

#### Summarization Example

```python
from langchain.agents.middleware import SummarizationMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[
        SummarizationMiddleware(
            model="gpt-4o-mini",
            trigger={"tokens": 4000},
            keep={"messages": 20},
        ),
    ],
)
```

When the conversation exceeds the token limit, `SummarizationMiddleware` automatically:
1. Summarizes older messages using a separate LLM call
2. Replaces them with a summary message in State (permanently)
3. Keeps recent messages intact for context

## Guardrails

Guardrails help you build safe, compliant AI applications by validating and filtering content at key points in your agent's execution.

### Built-in Guardrails

#### PII Detection

```python
from langchain.agents.middleware import PIIMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[
        PIIMiddleware(
            "email",
            strategy="redact",
            apply_to_input=True,
        ),
        PIIMiddleware(
            "credit_card",
            strategy="mask",
            apply_to_input=True,
        ),
        PIIMiddleware(
            "api_key",
            detector=r"sk-[a-zA-Z0-9]{32}",
            strategy="block",
            apply_to_input=True,
        ),
    ],
)
```

**Built-in PII types:**
- `email` - Email addresses
- `credit_card` - Credit card numbers (Luhn validated)
- `ip` - IP addresses
- `mac_address` - MAC addresses
- `url` - URLs

**Strategies:**
- `redact`: Replace with `[REDACTED_TYPE]`
- `mask`: Partially obscure
- `hash`: Replace with deterministic hash
- `block`: Raise exception

#### Human-in-the-Loop

```python
from langchain.agents.middleware import HumanInTheLoopMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool, send_email_tool, delete_database_tool],
    middleware=[
        HumanInTheLoopMiddleware(
            interrupt_on={
                "send_email": True,
                "delete_database": True,
                "search": False,
            }
        ),
    ],
    checkpointer=InMemorySaver(),
)
```

### Custom Guardrails

#### Before Agent Guardrails

```python
from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config
from langgraph.runtime import Runtime
from typing import Any

class ContentFilterMiddleware(AgentMiddleware):
    """Block requests containing banned keywords."""
    
    def __init__(self, banned_keywords: list[str]):
        super().__init__()
        self.banned_keywords = [kw.lower() for kw in banned_keywords]
    
    @hook_config(can_jump_to=["end"])
    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        if not state["messages"]:
            return None
        
        first_message = state["messages"][0]
        if first_message.type != "human":
            return None
        
        content = first_message.content.lower()
        
        for keyword in self.banned_keywords:
            if keyword in content:
                return {
                    "messages": [{
                        "role": "assistant",
                        "content": "I cannot process requests containing inappropriate content."
                    }],
                    "jump_to": "end"
                }
        
        return None
```

#### After Agent Guardrails

```python
from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config
from langchain.messages import AIMessage
from langchain.chat_models import init_chat_model
from langgraph.runtime import Runtime
from typing import Any

class SafetyGuardrailMiddleware(AgentMiddleware):
    """Use an LLM to evaluate response safety."""
    
    def __init__(self):
        super().__init__()
        self.safety_model = init_chat_model("gpt-4o-mini")
    
    @hook_config(can_jump_to=["end"])
    def after_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        if not state["messages"]:
            return None
        
        last_message = state["messages"][-1]
        if not isinstance(last_message, AIMessage):
            return None
        
        # Use a model to evaluate safety
        safety_prompt = f"""Evaluate if this response is safe and appropriate.
Respond with only 'SAFE' or 'UNSAFE'.

Response: {last_message.content}"""
        
        result = self.safety_model.invoke([{"role": "user", "content": safety_prompt}])
        
        if "UNSAFE" in result.content:
            last_message.content = "I cannot provide that response. Please rephrase your request."
        
        return None
```

### Combining Multiple Guardrails

```python
agent = create_agent(
    model="gpt-4o",
    tools=[search_tool, send_email_tool],
    middleware=[
        # Layer 1: Deterministic input filter
        ContentFilterMiddleware(banned_keywords=["hack", "exploit"]),
        
        # Layer 2: PII protection
        PIIMiddleware("email", strategy="redact", apply_to_input=True),
        PIIMiddleware("email", strategy="redact", apply_to_output=True),
        
        # Layer 3: Human approval for sensitive tools
        HumanInTheLoopMiddleware(interrupt_on={"send_email": True}),
        
        # Layer 4: Model-based safety check
        SafetyGuardrailMiddleware(),
    ],
)
```

## Runtime

LangChain's `create_agent` runs on LangGraph's runtime under the hood. The runtime provides:

1. **Context:** Static information like user id, db connections, or other dependencies
2. **Store:** A BaseStore instance used for long-term memory
3. **Stream writer:** An object used for streaming information via the "custom" stream mode

### Accessing Runtime in Tools

```python
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime

@dataclass
class Context:
    user_id: str

@tool
def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:
    """Fetch the user's email preferences from the store."""
    user_id = runtime.context.user_id
    
    preferences: str = "The user prefers you to write a brief and polite email."
    if runtime.store:
        if memory := runtime.store.get(("users",), user_id):
            preferences = memory.value["preferences"]
    
    return preferences
```

### Accessing Runtime in Middleware

```python
from dataclasses import dataclass
from langchain.agents.middleware import dynamic_prompt, ModelRequest
from langgraph.runtime import Runtime

@dataclass
class Context:
    user_name: str

@dynamic_prompt
def dynamic_system_prompt(request: ModelRequest) -> str:
    user_name = request.runtime.context.user_name
    system_prompt = f"You are a helpful assistant. Address the user as {user_name}."
    return system_prompt

agent = create_agent(
    model="gpt-5-nano",
    tools=[...],
    middleware=[dynamic_system_prompt],
    context_schema=Context
)

agent.invoke(
    {"messages": [{"role": "user", "content": "What's my name?"}]},
    context=Context(user_name="John Smith")
)
```

## Multi-Agent Systems

Multi-agent systems break complex applications into multiple specialized agents that work together.

### Multi-Agent Patterns

| Pattern | How it works | Control flow | Example use case |
|---------|--------------|--------------|------------------|
| **Tool Calling** | A supervisor agent calls other agents as tools | Centralized | Task orchestration, structured workflows |
| **Handoffs** | The current agent transfers control to another agent | Decentralized | Multi-domain conversations, specialist takeover |

### Tool Calling Pattern

In tool calling, one agent (the "controller") treats other agents as tools to be invoked when needed.

```python
from langchain.tools import tool
from langchain.agents import create_agent

subagent1 = create_agent(model="...", tools=[...])

@tool(
    "subagent1_name",
    description="subagent1_description"
)
def call_subagent1(query: str):
    result = subagent1.invoke({
        "messages": [{"role": "user", "content": query}]
    })
    return result["messages"][-1].content

agent = create_agent(model="...", tools=[call_subagent1])
```

### Controlling Input to Subagents

```python
from langchain.agents import AgentState
from langchain.tools import tool, ToolRuntime

class CustomState(AgentState):
    example_state_key: str

@tool("subagent1_name", description="subagent1_description")
def call_subagent1(query: str, runtime: ToolRuntime[None, CustomState]):
    # Apply logic to transform messages
    subagent_input = some_logic(query, runtime.state["messages"])
    result = subagent1.invoke({
        "messages": subagent_input,
        "example_state_key": runtime.state["example_state_key"]
    })
    return result["messages"][-1].content
```

### Controlling Output from Subagents

```python
from typing import Annotated
from langchain.agents import AgentState
from langchain.tools import InjectedToolCallId
from langchain.messages import ToolMessage
from langgraph.types import Command

@tool("subagent1_name", description="subagent1_description")
def call_subagent1(
    query: str,
    tool_call_id: Annotated[str, InjectedToolCallId],
) -> Command:
    result = subagent1.invoke({
        "messages": [{"role": "user", "content": query}]
    })
    return Command(update={
        "example_state_key": result["example_state_key"],
        "messages": [
            ToolMessage(
                content=result["messages"][-1].content,
                tool_call_id=tool_call_id
            )
        ]
    })
```

## Retrieval-Augmented Generation (RAG)

RAG addresses LLM limitations by fetching relevant external knowledge at query time.

### RAG Architectures

| Architecture | Description | Control | Flexibility | Latency |
|--------------|-------------|---------|--------------|---------|
| **2-Step RAG** | Retrieval always happens before generation | High | Low | Fast |
| **Agentic RAG** | LLM decides when and how to retrieve | Low | High | Variable |
| **Hybrid** | Combines both with validation steps | Medium | Medium | Variable |

### 2-Step RAG

In 2-Step RAG, retrieval always happens before generation:

```python
# 1. Retrieve relevant documents
retriever = vectorstore.as_retriever()
docs = retriever.invoke("user query")

# 2. Generate answer with retrieved context
response = model.invoke([
    {"role": "system", "content": "Answer using the provided context."},
    {"role": "user", "content": f"Context: {docs}\n\nQuestion: user query"}
])
```

### Agentic RAG

In Agentic RAG, an agent decides when and how to retrieve:

```python
import requests
from langchain.tools import tool
from langchain.agents import create_agent

@tool
def fetch_url(url: str) -> str:
    """Fetch text content from a URL"""
    response = requests.get(url, timeout=10.0)
    response.raise_for_status()
    return response.text

system_prompt = """\
Use fetch_url when you need to fetch information from a web-page; quote relevant snippets.
"""

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[fetch_url],  # A tool for retrieval
    system_prompt=system_prompt,
)
```

### Building a Knowledge Base

A knowledge base is a repository of documents used during retrieval. Typical workflow:

1. **Document Loaders:** Ingest data from external sources
2. **Text Splitters:** Break large docs into smaller chunks
3. **Embedding Models:** Turn text into vectors
4. **Vector Stores:** Store and search embeddings
5. **Retrievers:** Return documents given a query

```python
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# Load documents
loader = PyPDFLoader("document.pdf")
documents = loader.load()

# Split into chunks
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = text_splitter.split_documents(documents)

# Create embeddings and vector store
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(chunks, embeddings)

# Create retriever
retriever = vectorstore.as_retriever()
```

## Testing

Thorough testing is essential for production-ready agents.

### Unit Testing

#### Mocking Chat Model

```python
from langchain_core.language_models.fake_chat_models import GenericFakeChatModel
from langchain.messages import AIMessage
from langchain_core.messages.tool import ToolCall

model = GenericFakeChatModel(messages=iter([
    AIMessage(content="", tool_calls=[ToolCall(name="foo", args={"bar": "baz"}, id="call_1")]),
    "bar"
]))

model.invoke("hello")
# AIMessage(content='', ..., tool_calls=[...])
```

#### InMemorySaver Checkpointer

```python
from langgraph.checkpoint.memory import InMemorySaver
from langchain.messages import HumanMessage

agent = create_agent(
    model,
    tools=[],
    checkpointer=InMemorySaver()
)

# First invocation
agent.invoke(HumanMessage(content="I live in Sydney, Australia."))

# Second invocation: the first message is persisted
agent.invoke(HumanMessage(content="What's my local time?"))
```

### Integration Testing

#### Trajectory Match Evaluator

```python
from agentevals.trajectory.match import create_trajectory_match_evaluator
from langchain.messages import HumanMessage, AIMessage, ToolMessage

evaluator = create_trajectory_match_evaluator(
    trajectory_match_mode="strict",  # or "unordered", "subset", "superset"
)

def test_weather_tool_called_strict():
    result = agent.invoke({
        "messages": [HumanMessage(content="What's the weather in San Francisco?")]
    })
    
    reference_trajectory = [
        HumanMessage(content="What's the weather in San Francisco?"),
        AIMessage(content="", tool_calls=[
            {"id": "call_1", "name": "get_weather", "args": {"city": "San Francisco"}}
        ]),
        ToolMessage(content="It's 75 degrees and sunny.", tool_call_id="call_1"),
        AIMessage(content="The weather in San Francisco is 75 degrees and sunny."),
    ]
    
    evaluation = evaluator(result["messages"], reference_trajectory)
    assert evaluation.passed
```

#### LLM-as-Judge Evaluator

```python
from agentevals.trajectory.judge import create_llm_judge_evaluator

evaluator = create_llm_judge_evaluator(
    judge_model="gpt-4o",
    rubric="The agent should use the weather tool when asked about weather.",
)

def test_weather_agent():
    result = agent.invoke({
        "messages": [HumanMessage(content="What's the weather?")]
    })
    
    evaluation = evaluator(result["messages"])
    assert evaluation.passed
```

## Deployment

### LangSmith Studio

LangSmith Studio is a free visual interface for developing and testing LangChain agents locally.

#### Setup

1. **Install LangGraph CLI:**
```bash
pip install --upgrade "langgraph-cli[inmem]"
```

2. **Create agent file:**
```python
# agent.py
from langchain.agents import create_agent

def send_email(to: str, subject: str, body: str):
    """Send an email"""
    return f"Email sent to {to}"

agent = create_agent(
    "gpt-4o",
    tools=[send_email],
    system_prompt="You are an email assistant.",
)
```

3. **Create langgraph.json:**
```json
{
  "dependencies": ["."],
  "graphs": {
    "agent": "./agent.py:agent"
  },
  "env": ".env"
}
```

4. **Start development server:**
```bash
langgraph dev
```

Your agent is now accessible at `http://127.0.0.1:2024` and through Studio UI.

### Production Deployment

For production, consider:

1. **Persistent Checkpointer:** Use database-backed checkpointers (e.g., `AsyncPostgresSaver`)
2. **Persistent Store:** Use database-backed stores for long-term memory
3. **Error Handling:** Implement robust error handling and retries
4. **Monitoring:** Use LangSmith for observability
5. **Rate Limiting:** Implement rate limiting for API calls
6. **Caching:** Cache model responses when appropriate
7. **Security:** Implement proper authentication and authorization

## Best Practices

### Implementation Best Practices

1. **Start Simple:** Begin with static prompts and tools, add dynamics only when needed
2. **Test Incrementally:** Add one context engineering feature at a time
3. **Monitor Performance:** Track model calls, token usage, and latency
4. **Use Built-in Middleware:** Leverage `SummarizationMiddleware`, `PIIMiddleware`, etc.
5. **Document Your Context Strategy:** Make it clear what context is being passed and why
6. **Understand Transient vs Persistent:** Model context changes are transient, life-cycle context changes persist

### Optimization Tips

1. **Model Selection:** Use smaller models for simple tasks, larger models for complex reasoning
2. **Tool Selection:** Dynamically filter tools to reduce prompt size
3. **Summarization:** Use summarization middleware to manage long conversations
4. **Caching:** Cache model responses for repeated queries
5. **Batching:** Batch tool calls when possible

### Common Pitfalls to Avoid

1. **Too Many Tools:** Overwhelming the model with too many tools
2. **Poor Tool Descriptions:** Vague or unclear tool descriptions lead to incorrect usage
3. **Ignoring Context:** Not providing enough context or providing irrelevant context
4. **No Error Handling:** Not handling tool failures gracefully
5. **Memory Leaks:** Not managing conversation state properly
6. **Cost Overruns:** Not monitoring token usage and model costs

### Guidelines

1. **Tool Naming:** Use clear, descriptive names for tools
2. **Tool Descriptions:** Write detailed docstrings that explain when and how to use tools
3. **System Prompts:** Be specific and actionable in system prompts
4. **Error Messages:** Provide helpful error messages from tools
5. **State Management:** Use appropriate state management (State vs Store vs Runtime Context)

## Limitations and Assumptions

### Stated Limitations

1. **LLM Reliability:** LLMs can be unreliable and may make mistakes
2. **Context Windows:** Limited by model context windows
3. **Latency:** Agent loops can be slow due to multiple model calls
4. **Cost:** Multiple model calls can be expensive
5. **Non-Deterministic:** Agent behavior can vary between runs

### Assumptions

1. **Model Availability:** Assumes LLM providers are available and responsive
2. **Tool Reliability:** Assumes tools are reliable and return expected formats
3. **State Consistency:** Assumes state management is consistent
4. **Network Connectivity:** Assumes network connectivity for API calls

### Constraints

1. **Python 3.10+:** Requires Python 3.10 or higher
2. **API Keys:** Requires valid API keys for LLM providers
3. **Dependencies:** Requires various dependencies for different features
4. **Memory:** Requires sufficient memory for large conversations

## Related Techniques and References

### Related Techniques

1. **LangGraph:** Low-level agent orchestration framework
2. **Retrieval-Augmented Generation (RAG):** Enhancing LLMs with external knowledge
3. **Function Calling:** Standard protocol for tool calling
4. **Model Context Protocol (MCP):** Standardized protocol for providing tools and context to LLMs

### Key References

- **LangChain Documentation:** https://docs.langchain.com/
- **LangGraph Documentation:** https://langchain-ai.github.io/langgraph/
- **LangSmith:** https://smith.langchain.com/
- **Model Context Protocol:** https://modelcontextprotocol.io/

## Implementation Checklist

### Prerequisites

- [ ] Python 3.10+ installed
- [ ] LangChain package installed
- [ ] Provider-specific packages installed (e.g., `langchain-openai`)
- [ ] API keys configured as environment variables
- [ ] Basic understanding of Python programming

### Setup Steps

1. [ ] Install LangChain: `pip install -U langchain`
2. [ ] Install provider package: `pip install -U langchain-openai` (or other provider)
3. [ ] Set environment variable: `export OPENAI_API_KEY=your_key`
4. [ ] Verify installation: `python -c "import langchain; print(langchain.__version__)"`

### Implementation Steps

1. [ ] Define system prompt
2. [ ] Create tools using `@tool` decorator
3. [ ] Initialize model using `init_chat_model`
4. [ ] Create agent using `create_agent`
5. [ ] Test basic agent functionality
6. [ ] Add memory (checkpointer) if needed
7. [ ] Add middleware for cross-cutting concerns
8. [ ] Add structured output if needed
9. [ ] Add long-term memory (store) if needed
10. [ ] Test with various inputs
11. [ ] Add error handling
12. [ ] Add logging and monitoring
13. [ ] Deploy to production

### Testing Steps

1. [ ] Write unit tests with mocked models
2. [ ] Write integration tests with real models
3. [ ] Test tool calling behavior
4. [ ] Test memory persistence
5. [ ] Test error handling
6. [ ] Test edge cases
7. [ ] Performance testing
8. [ ] Load testing

## Additional Resources

### Documentation

- **LangChain Python Docs:** https://docs.langchain.com/oss/python/langchain
- **LangGraph Docs:** https://langchain-ai.github.io/langgraph/
- **API Reference:** https://reference.langchain.com/

### Tutorials

- **Quickstart Guide:** https://docs.langchain.com/oss/python/langchain/quickstart
- **Agent Tutorial:** https://docs.langchain.com/oss/python/langchain/agents
- **RAG Tutorial:** https://docs.langchain.com/oss/python/langchain/rag

### Community

- **GitHub:** https://github.com/langchain-ai/langchain
- **Discord:** https://discord.gg/langchain
- **Twitter:** @LangChainAI

---

**END OF LANGCHAIN COMPREHENSIVE GUIDE**

This MDC file provides a complete reference for building AI agents with LangChain. It covers all major concepts, patterns, and best practices needed to successfully deploy production-ready AI agents.
